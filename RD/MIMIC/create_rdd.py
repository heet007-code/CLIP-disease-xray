# -*- coding: utf-8 -*-
"""RDD

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FxphpNJ7ztFjzhTARJnmRD730j_LOD-9
"""

#completing physionet requirements and privacy agreement pre-requisite to this code
!pip install physionet-dataloader
#replace 'username' with your credentials
!wget -r -N -c -np --user username --ask-password https://physionet.org/files/cxr-lt-iccv-workshop-cvamd/2.0.0/
!unzip -o cxr-lt-iccv-workshop-cvamd-2.0.0.zip -d cxr-lt

import pandas as pd


labels = pd.read_csv("physionet.org/files/cxr-lt-iccv-workshop-cvamd/2.0.0/cxr-lt-2024/labels.csv")


rare_labels = [
    'Azygos Lobe',
    'Hydropneumothorax',
    'Pulmonary Embolism',
    'Pulmonary Hypertension',
    'Round Atelectasis',
    'Tuberculosis',
    'Cardiomyopathy',
]



available_labels = [label for label in rare_labels if label in labels.columns]
print("Available rare labels in dataset:", available_labels)


rare_df = labels[labels[available_labels].sum(axis=1) > 0]


print(rare_df[['subject_id', 'study_id', 'dicom_id'] + available_labels].head())


rare_df.to_csv("rare_disease_cxr_subset.csv", index=False)

def get_download_url(row):
    subject_id = str(row['subject_id'])
    study_id = row['study_id']
    dicom_id = row['dicom_id']
    folder = f"p{subject_id[:2]}/p{subject_id}/{study_id}/"
    return f"https://physionet.org/files/mimic-cxr-jpg/2.0.0/files/{folder}{dicom_id}.jpg"


rare_df['download_url'] = rare_df.apply(get_download_url, axis=1)

print(rare_df[['dicom_id', 'download_url']].head())

rare_df.to_csv("rare_disease_download_list.csv", index=False)

rare_df['download_url'].to_csv('urls.txt', index=False, header=False)

!apt-get install wget

!mkdir -p rare_disease_xrays

#replace 'username' with your credentials
!wget --user=username --ask-password -i urls.txt -P rare_disease_xrays/

for label in available_labels:
    count = (rare_df[label] == 1).sum()
    print(f"{label}: {count} positive samples")

import os
import pandas as pd
import numpy as np
import shutil
from tqdm import tqdm


rare_df = pd.read_csv("rare_disease_download_list.csv")


rare_labels = [
    'Azygos Lobe',
    'Hydropneumothorax',
    'Pulmonary Embolism',
    'Pulmonary Hypertension',
    'Tuberculosis',
    'Cardiomyopathy',
]


np.random.seed(42)


base_dir = "few_shot"
os.makedirs(base_dir, exist_ok=True)


local_images_path = "rare_disease_xrays"


available_images = set([fname.replace(".jpg", "") for fname in os.listdir(local_images_path) if fname.endswith(".jpg")])

print(f"ðŸ”Ž Found {len(available_images)} available images locally.")


rare_df = rare_df[rare_df['dicom_id'].isin(available_images)]
print(f"âœ… {len(rare_df)} entries in rare_df after filtering for available images.")


few_shot_splits = {}


used_ids = set()


def copy_image(dicom_id, save_path):
    source_file = os.path.join(local_images_path, dicom_id + ".jpg")
    if os.path.exists(source_file):
        shutil.copy(source_file, save_path)
    else:
        print(f"Could not find {dicom_id}.jpg locally!")


for shots in [1, 2, 4, 8, 16]:
    selected_rows = []

    for label in rare_labels:
        positive_rows = rare_df[(rare_df[label] == 1) & (~rare_df['dicom_id'].isin(used_ids))]

        if len(positive_rows) < shots:
            raise ValueError(f"Not enough positive samples for {label} to create {shots}-shot set.")

        sampled = positive_rows.sample(n=shots, replace=False)
        used_ids.update(sampled['dicom_id'].tolist())
        selected_rows.append(sampled)

    few_shot_df = pd.concat(selected_rows).drop_duplicates()
    few_shot_splits[f"{shots}_shot"] = few_shot_df

    # Save CSV
    split_dir = os.path.join(base_dir, f"{shots}_shot")
    os.makedirs(split_dir, exist_ok=True)
    few_shot_df.to_csv(os.path.join(split_dir, f"few_shot_{shots}_per_disease.csv"), index=False)

    print(f" {shots}-shot split created with {len(few_shot_df)} images.")


    print(f"ðŸ“‚ Copying images for {shots}-shot split...")
    for idx, row in tqdm(few_shot_df.iterrows(), total=len(few_shot_df)):
        dicom_id = row['dicom_id']
        filename = f"{dicom_id}.jpg"
        save_path = os.path.join(split_dir, filename)

        if not os.path.exists(save_path):
            copy_image(dicom_id, save_path)

    print(f" All images copied for {shots}-shot split.\n")

print(" All few-shot datasets and images organized locally!")

import shutil


shutil.make_archive('few_shot_dataset', 'zip', 'few_shot')

print("few_shot_dataset.zip created!")